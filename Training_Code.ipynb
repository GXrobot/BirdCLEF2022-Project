{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4vzsXtbgHMi"
      },
      "source": [
        "Training Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naJXb7fNiyFu"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLAB = False\n",
        "# On Windows Run in ENSC_413 Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtLTAzrn5Q5d",
        "outputId": "b082b206-ded2-4ee0-abad-920559824704"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_zReHXbriM1",
        "outputId": "b98b9cb8-5c5a-4adf-8e48-861425a9302b"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    # ! cp -vr /content/drive/MyDrive/audio_images/ /content/audio_images\n",
        "    # ! cp -vr /content/drive/MyDrive/audio_images-20220324T215740Z-001.zip /content/\n",
        "    ! cp -vr /content/drive/MyDrive/audio_images.tar.gz /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6q6hslG3pSN",
        "outputId": "5ee932b9-e167-4fa7-d6b9-a9bd7130a4a9"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    ! ls -alt /content/\n",
        "    ! mkdir /content/audio_images\n",
        "    ! tar -zxvf audio_images.tar.gz \n",
        "    # ! unzip /content/audio_images-20220324T215740Z-001.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rfePjkjwlbh",
        "outputId": "3a48cbad-30a3-49e8-a3c9-c212e753b8db"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    ! du -h /content/audio_images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-TkYWqd5ZG8"
      },
      "source": [
        "Paths and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUlkmd-MgFbE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, gc\n",
        "import librosa as lb\n",
        "import librosa.display as lbd\n",
        "\n",
        "# from kaggle_datasets import KaggleDatasets\n",
        "import tensorflow as tf, re, math\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "# force a channel ordering\n",
        "from keras import backend\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from functools import lru_cache\n",
        "\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY4sDFqK5ZaR"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    # TRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"/content/drive/MyDrive/audio_images\")\n",
        "    TRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"/content/audio_images\")\n",
        "\n",
        "    MODEL_SAVE_ROOT = Path(\"/content/drive/MyDrive/model_save\")\n",
        "    MODEL_SAVE_NAME = 'BirdClef2022-ResNet50V2_model.h5'\n",
        "else:\n",
        "    # TRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"/content/drive/MyDrive/audio_images\")\n",
        "    TRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(r\"C:\\Users\\xuewi\\Desktop\\SFU\\ENSC_413\\audio_images\")\n",
        "\n",
        "    MODEL_SAVE_ROOT = Path(r\"C:\\Users\\xuewi\\Desktop\\SFU\\ENSC_413\\BirdCLEF2022-Project\\model_save\")\n",
        "    MODEL_SAVE_NAME = 'Local-ResNet50V2_model.h5'\n",
        "\n",
        "\n",
        "LOAD_SAVED_MODEL = False\n",
        "\n",
        "# Threshold for no-call detector\n",
        "BIRD_CALL_PROB = 0.5\n",
        "\n",
        "# No Call Label\n",
        "NO_CALL = \"no_call\"\n",
        "\n",
        "# NUM_FOLDS = 5\n",
        "\n",
        "if COLAB:\n",
        "    BATCH_SIZE = 128\n",
        "else:\n",
        "    BATCH_SIZE = 96\n",
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4ly87XooWI"
      },
      "source": [
        "Some Birds Only Have A Few Training Samples and no-call will reduce their values even more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbTnhJwsouEv"
      },
      "outputs": [],
      "source": [
        "# ignore these birds for no-call\n",
        "# samples too little to filter through no-call\n",
        "NO_CALL_IGNORE = [ 'akikik', 'brnboo', 'bubsan', 'bulpet', 'coopet', 'crehon', 'ercfra', 'hawpet1', 'layalb', 'lessca', 'magpet1', 'mauala', 'pomjae', 'puaioh', 'shtsan']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2tWvp73ivlJ"
      },
      "source": [
        "Connect To TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEBEFDqpfAJo"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"TPU\" # \"TPU\" or \"GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfktkchNf5r1",
        "outputId": "475de503-1166-48a2-ef5a-74ce8cb28411"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/itsuki9180/birdcall-using-tpu-train/notebook\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except _:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doJ2zx6Ri0am"
      },
      "source": [
        "Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq0eR165i2El",
        "outputId": "28511c48-6bd1-4b79-e8bc-05b15035d32d"
      },
      "outputs": [],
      "source": [
        "x_data = []\n",
        "y_data= []\n",
        "\n",
        "if COLAB:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/no_call_detect/nocalldetection_for_shortaudio_fold0.csv')\n",
        "else:\n",
        "    df = pd.read_csv(r'C:\\Users\\xuewi\\Desktop\\SFU\\ENSC_413\\BirdCLEF2022-Project\\no_call_detect\\nocalldetection_for_shortaudio_fold0.csv')\n",
        "for row in tqdm(df.itertuples(False)):\n",
        "    mels = np.load(str((TRAIN_AUDIO_IMAGES_SAVE_ROOT/row.filename).as_posix() + \".npy\"))\n",
        "    # print(mels.shape)\n",
        "\n",
        "    # extract the calculated call probability\n",
        "    temp_str = row.nocalldetection\n",
        "    call_prob = [float(x) for x in temp_str.split()]\n",
        "\n",
        "    # for each image, append each audio segment\n",
        "    for i in range(len(mels)):\n",
        "        x_data.append( (str((TRAIN_AUDIO_IMAGES_SAVE_ROOT/row.filename).as_posix() + \".npy\"), i) )\n",
        "\n",
        "        if (call_prob[i] >= BIRD_CALL_PROB or row.primary_label in NO_CALL_IGNORE):\n",
        "            y_data.append(row.primary_label)\n",
        "        else:\n",
        "            y_data.append(NO_CALL)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwVx9GJFnHXQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVjV_eFOJC91",
        "outputId": "983ae06b-aa27-4816-d039-84e67d37a15d"
      },
      "outputs": [],
      "source": [
        "print(len(x_data))\n",
        "print(len(y_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCOXEUh0wUxe"
      },
      "source": [
        "Label Encode the Output and Save the Mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVtZKnILN-Mg",
        "outputId": "dc948694-f000-41fb-e5e5-48fe6b62b1bf"
      },
      "outputs": [],
      "source": [
        "LOAD_LABELS = True\n",
        "\n",
        "le = LabelEncoder()\n",
        "if LOAD_LABELS:\n",
        "    le.classes_ = np.load(MODEL_SAVE_ROOT/\"classes.npy\")\n",
        "y_label = le.fit_transform(y_data)\n",
        "le_name_mapping = dict(zip(le.classes_.astype(str), le.transform(le.classes_)))\n",
        "print(le_name_mapping)\n",
        "\n",
        "if not LOAD_LABELS:\n",
        "    np.save(MODEL_SAVE_ROOT/\"classes.npy\", le.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLwOWjJyUw0z",
        "outputId": "6c167aed-81fb-4eb7-a89f-4d2af9270dc6"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    print(x_data[i])\n",
        "    print(y_label[i])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3XTSGSUhP1b"
      },
      "source": [
        "Split Into Train and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl-k6mjxhPL4"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_label, test_size=0.2, stratify=y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku17UAravDqt"
      },
      "source": [
        "Checking Train / Val Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0sC8FkQjYY6",
        "outputId": "ad3e4290-01f0-45ed-873f-ad5978cbe687"
      },
      "outputs": [],
      "source": [
        "print(type(y_label))\n",
        "counts = np.bincount(y_label)\n",
        "print(counts)\n",
        "\n",
        "\n",
        "y = le.inverse_transform(y_label)\n",
        "print(y)\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "values = dict(zip(unique, counts))\n",
        "d = dict((k, v) for k, v in values.items() if v <= 20)\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4-CoEzojYdm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV-uHxXMWi-U"
      },
      "outputs": [],
      "source": [
        "def normalize(image):\n",
        "        image = image.astype(\"float32\", copy=False) / 255.0\n",
        "        image = np.stack([image, image, image])\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y_7AFilW3W2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScPCHZBGaTlY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# cache file loads?, doesn't seem to work\n",
        "@lru_cache(maxsize=None)\n",
        "def load_data(im_path):\n",
        "    return np.load(im_path)\n",
        "\n",
        "\n",
        "\n",
        "# https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n",
        "class CustomDataGen(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "\n",
        "        # Print Time\n",
        "        now = datetime.now()\n",
        "        current_time = now.strftime(\"%H:%M:%S\")\n",
        "        print(\"Current Time =\", current_time)\n",
        "\n",
        "        # Shuffle Data at the End of Epoch\n",
        "        if self.shuffle:\n",
        "            c = list(zip(self.x_data, self.y_data))\n",
        "            random.shuffle(c)\n",
        "            x_data, y_data = zip(*c)\n",
        "        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # print(f\"Index {index}\")\n",
        "        \n",
        "        x_batch = self.x_data[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        y_batch = self.y_data[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        # print(f\"x_batch {x_batch}\")\n",
        "\n",
        "        x_images = self.__get_data(x_batch)\n",
        "        y_labels = self.__get_output(y_batch)\n",
        "\n",
        "        x_images = np.array(x_images)\n",
        "\n",
        "        # ensure type TODO REMOVEME\n",
        "        # print(type(x_images))\n",
        "        # assert isinstance(x_images, (np.ndarray, np.generic))\n",
        "        # assert isinstance(y_labels, (np.ndarray, np.generic))\n",
        "\n",
        "        # print(f\"x_images shape {x_images.shape}\")\n",
        "        return x_images, y_labels\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data) // self.batch_size\n",
        "\n",
        "    def __get_data(self, x_batch):\n",
        "        x_im = []\n",
        "        for index, tup in enumerate(x_batch):\n",
        "            file_name = tup[0]\n",
        "            mel_num = tup[1]\n",
        "            # mels = np.load(str((TRAIN_AUDIO_IMAGES_SAVE_ROOT/file_name).as_posix()))\n",
        "            mels = load_data(str((TRAIN_AUDIO_IMAGES_SAVE_ROOT/file_name).as_posix()))\n",
        "            norm_im = normalize(mels[mel_num])\n",
        "            x_im.append(norm_im)\n",
        "        return x_im\n",
        "\n",
        "\n",
        "    def __get_output(self, y_batch):\n",
        "        # num classes from the label encoder\n",
        "        num_classes = len(le.classes_)\n",
        "        # Target for 0.99 instead of 1\n",
        "        return tf.keras.utils.to_categorical(y_batch, num_classes) * 0.99\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRps4Ze7gcDj",
        "outputId": "240f4050-0356-4f70-f75b-1520e45daca0"
      },
      "outputs": [],
      "source": [
        "# force channels-first ordering\n",
        "backend.set_image_data_format('channels_first')\n",
        "print(backend.image_data_format())\n",
        "\n",
        "base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
        "    include_top=False,\n",
        "    input_shape=(3, 128, 281),\n",
        "    weights='imagenet',\n",
        ")\n",
        "x = base_model.output\n",
        "# https://cv-tricks.com/keras/understand-implement-resnets/\n",
        "# Global Average Pooling\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "d1 = Dense(1024, activation='relu')(x)\n",
        "d1 = Dropout(0.5)(d1)\n",
        "predictions = Dense(153, activation='softmax')(d1)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "        learning_rate=1e-3,\n",
        "        epsilon=1e-07,\n",
        "      )\n",
        "model.compile(opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr9crllaNmEY"
      },
      "source": [
        "Training Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGoqrMbgMcg0"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/enukuro/108th-place-solution-birdcall-keras-tpu/notebook\n",
        "es = tf.keras.callbacks.EarlyStopping(\n",
        "              monitor='val_loss', \n",
        "              verbose=1, \n",
        "              patience=6)\n",
        "sv = tf.keras.callbacks.ModelCheckpoint(\n",
        "              MODEL_SAVE_ROOT/MODEL_SAVE_NAME,\n",
        "              monitor='val_loss',\n",
        "              verbose=1,\n",
        "              save_best_only=True) #, save_weights_only=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "              monitor='val_loss', \n",
        "              verbose=1, \n",
        "              factor=0.2, \n",
        "              patience=5, \n",
        "              min_delta=0.0001, \n",
        "              cooldown=1, \n",
        "              min_lr=1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD9DiAlazwxB"
      },
      "outputs": [],
      "source": [
        "# x_train, x_val, y_train, y_val\n",
        "\n",
        "traingen = CustomDataGen(x_train, y_train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "valgen = CustomDataGen(x_val, y_val, batch_size = BATCH_SIZE, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDgbSRKajnXr",
        "outputId": "4664fc1a-2161-4501-a5b9-f6ef108125ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1207/1207 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9097Current Time = 13:40:06\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00755\n",
            "1207/1207 [==============================] - 540s 448ms/step - loss: 0.0036 - accuracy: 0.9097 - val_loss: 0.0125 - val_accuracy: 0.7110 - lr: 0.0010\n",
            "Current Time = 13:40:06\n",
            "Epoch 8/30\n",
            "1207/1207 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9303Current Time = 13:49:24\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00755\n",
            "1207/1207 [==============================] - 559s 463ms/step - loss: 0.0030 - accuracy: 0.9303 - val_loss: 0.0092 - val_accuracy: 0.7860 - lr: 0.0010\n",
            "Current Time = 13:49:25\n",
            "Epoch 9/30\n",
            "1207/1207 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9451Current Time = 13:57:37\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00755\n",
            "1207/1207 [==============================] - 493s 408ms/step - loss: 0.0025 - accuracy: 0.9451 - val_loss: 0.0114 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Current Time = 13:57:38\n",
            "Epoch 10/30\n",
            "1207/1207 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9577Current Time = 14:05:59\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00755\n",
            "1207/1207 [==============================] - 501s 415ms/step - loss: 0.0021 - accuracy: 0.9577 - val_loss: 0.0118 - val_accuracy: 0.7585 - lr: 0.0010\n",
            "Current Time = 14:05:59\n",
            "Epoch 11/30\n",
            "1207/1207 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9663Current Time = 14:14:47\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00755\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "1207/1207 [==============================] - 528s 437ms/step - loss: 0.0018 - accuracy: 0.9663 - val_loss: 0.0087 - val_accuracy: 0.8114 - lr: 0.0010\n",
            "Current Time = 14:14:47\n",
            "Epoch 12/30\n",
            "1207/1207 [==============================] - ETA: 0s - loss: 7.9034e-04 - accuracy: 0.9933Current Time = 14:23:30\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00755\n",
            "1207/1207 [==============================] - 523s 433ms/step - loss: 7.9034e-04 - accuracy: 0.9933 - val_loss: 0.0077 - val_accuracy: 0.8609 - lr: 2.0000e-04\n",
            "Epoch 00012: early stopping\n"
          ]
        }
      ],
      "source": [
        "STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE\n",
        "VALIDATION_STEP = len(x_val) // BATCH_SIZE\n",
        "\n",
        "if LOAD_SAVED_MODEL:\n",
        "    model = keras.models.load_model(MODEL_SAVE_ROOT/'BirdClef2022-ResNet50V2_model.h5')\n",
        "\n",
        "history = model.fit(\n",
        "    traingen,\n",
        "    epochs = EPOCHS,\n",
        "    steps_per_epoch= STEPS_PER_EPOCH,\n",
        "    callbacks = [es, sv, reduce_lr],\n",
        "    validation_data=valgen,\n",
        "    validation_steps = VALIDATION_STEP\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "with open(MODEL_SAVE_ROOT/'trainHistoryDict', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8BQW-QKo9XhW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---- display history ----\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('train_test_accuracy_vgg16_augmentation.png')\n",
        "plt.clf() # clear figure\n",
        "# summarize history for loss (binary cross-entropy)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('binary cross-entropy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('train_test_loss_vgg16_augmentation.png')\n",
        "plt.clf()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPaD3k7Qt83WFo9fJM4gf8z",
      "collapsed_sections": [],
      "mount_file_id": "1bXvU4U2vx9Gh2wb6H9bziDQ0-iGHxo79",
      "name": "Training_Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
