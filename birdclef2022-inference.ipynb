{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Code modified from Attila Ambrus's notebook on Kaggle for Basic Submission\n# https://www.kaggle.com/code/ambrusattila/basic-submission-without-scoring-error/notebook","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.289781Z","iopub.execute_input":"2022-04-05T01:26:28.290066Z","iopub.status.idle":"2022-04-05T01:26:28.293731Z","shell.execute_reply.started":"2022-04-05T01:26:28.290028Z","shell.execute_reply":"2022-04-05T01:26:28.292926Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import os\nimport json \nimport librosa\nimport numpy as np\nimport pandas as pd\n\nimport librosa as lb\nimport librosa.display as lbd\nimport soundfile as sf\nfrom  soundfile import SoundFile\n\nfrom  IPython.display import Audio\nfrom pathlib import Path\n\nfrom matplotlib import pyplot as plt\n\n# TF\nfrom tensorflow import keras\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import LabelEncoder\n\n","metadata":{"executionInfo":{"elapsed":443,"status":"ok","timestamp":1645034298568,"user":{"displayName":"Attila Ambrus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaJ4A8UrN6evHJH1uiMr07w_zMQTSPfnDX2MTdnA=s64","userId":"16425370566673712155"},"user_tz":-60},"id":"htI0iVj1ybxz","papermill":{"duration":2.462917,"end_time":"2022-03-01T08:55:26.49349","exception":false,"start_time":"2022-03-01T08:55:24.030573","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-05T01:26:28.300869Z","iopub.execute_input":"2022-04-05T01:26:28.301101Z","iopub.status.idle":"2022-04-05T01:26:28.309919Z","shell.execute_reply.started":"2022-04-05T01:26:28.301073Z","shell.execute_reply":"2022-04-05T01:26:28.309095Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"work_dir=\"/kaggle/working\"       \nmels_dir=\"/kaggle/working/mels\"","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1645034302267,"user":{"displayName":"Attila Ambrus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaJ4A8UrN6evHJH1uiMr07w_zMQTSPfnDX2MTdnA=s64","userId":"16425370566673712155"},"user_tz":-60},"id":"9a0vFsuhyntp","papermill":{"duration":0.014645,"end_time":"2022-03-01T08:55:26.516608","exception":false,"start_time":"2022-03-01T08:55:26.501963","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-05T01:26:28.311705Z","iopub.execute_input":"2022-04-05T01:26:28.313128Z","iopub.status.idle":"2022-04-05T01:26:28.319548Z","shell.execute_reply.started":"2022-04-05T01:26:28.313100Z","shell.execute_reply":"2022-04-05T01:26:28.318771Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"input_dir=\"/kaggle/input/birdclef-2022\"\nmodel_dir= Path(\"/kaggle/input/BirdClef-Model\")\n\n#model_name= Path(\"Local-ResNet50V2_model.h5\")\n#classes_np = Path(\"classes.npy\")\nmodel_name= Path(\"ResNet50V2_model_multilabel_sigmoid_v2.h5\")\nclasses_np = Path(\"classes_only_birds.npy\")\n","metadata":{"executionInfo":{"elapsed":3277,"status":"ok","timestamp":1645034306372,"user":{"displayName":"Attila Ambrus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaJ4A8UrN6evHJH1uiMr07w_zMQTSPfnDX2MTdnA=s64","userId":"16425370566673712155"},"user_tz":-60},"id":"3qAC_e4O9hxg","outputId":"b32208c2-cbd4-4a3b-b035-b49bde9f9d73","papermill":{"duration":0.013084,"end_time":"2022-03-01T08:55:26.536597","exception":false,"start_time":"2022-03-01T08:55:26.523513","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-05T01:26:28.321066Z","iopub.execute_input":"2022-04-05T01:26:28.321557Z","iopub.status.idle":"2022-04-05T01:26:28.332286Z","shell.execute_reply.started":"2022-04-05T01:26:28.321506Z","shell.execute_reply":"2022-04-05T01:26:28.331535Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/itsuki9180/birdcall-using-tpu-train/notebook\nDEVICE = \"TPU\" # \"TPU\" or \"GPU\"\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.335492Z","iopub.execute_input":"2022-04-05T01:26:28.335741Z","iopub.status.idle":"2022-04-05T01:26:28.346800Z","shell.execute_reply.started":"2022-04-05T01:26:28.335688Z","shell.execute_reply":"2022-04-05T01:26:28.345874Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"connecting to TPU...\nCould not connect to TPU\nUsing default strategy for CPU and single GPU\nNum GPUs Available:  1\nREPLICAS: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr//10)\n        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr//(10*4))\n        self.kwargs = kwargs\n\n    def __call__(self, y):\n\n        melspec = lb.feature.melspectrogram(\n            y=y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n        )\n\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.349409Z","iopub.execute_input":"2022-04-05T01:26:28.349928Z","iopub.status.idle":"2022-04-05T01:26:28.359342Z","shell.execute_reply.started":"2022-04-05T01:26:28.349890Z","shell.execute_reply":"2022-04-05T01:26:28.358501Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) / (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) / (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n \ndef crop_or_pad(y, length, is_train=True, start=None):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n        \n        n_repeats = length // len(y)\n        epsilon = length % len(y)\n        \n        y = np.concatenate([y]*n_repeats + [y[:epsilon]])\n        \n    elif len(y) > length:\n        if not is_train:\n            start = start or 0\n        else:\n            start = start or np.random.randint(len(y) - length)\n\n        y = y[start:start + length]\n\n    return y","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.360723Z","iopub.execute_input":"2022-04-05T01:26:28.361002Z","iopub.status.idle":"2022-04-05T01:26:28.373921Z","shell.execute_reply.started":"2022-04-05T01:26:28.360965Z","shell.execute_reply":"2022-04-05T01:26:28.373123Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Mel Spec Inputs\n\nSR = 32_000\nDURATION = 7 \nSEED = 666\n\n# Prediction Threshold\nPRED_THRESHOLD = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.376300Z","iopub.execute_input":"2022-04-05T01:26:28.376563Z","iopub.status.idle":"2022-04-05T01:26:28.382061Z","shell.execute_reply.started":"2022-04-05T01:26:28.376527Z","shell.execute_reply":"2022-04-05T01:26:28.381327Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class AudioToImage:\n    def __init__(self, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr//2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n                                                 fmax=self.fmax)\n        \n    def audio_to_image(self, audio):\n        melspec = self.mel_spec_computer(audio) \n        image = mono_to_color(melspec)\n#         image = normalize(image, mean=None, std=None)\n        return image\n\n    def __call__(self, filepath, save=True):\n#       max_audio_duration = 10*self.duration\n#       init_audio_length = max_audio_duration*row.sr\n        \n#       start = 0 if row.duration <  max_audio_duration else np.random.randint(row.frames - init_audio_length)\n    \n      audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n\n      if self.resample and orig_sr != self.sr:\n        audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n        \n      audios = [audio[i:i+self.audio_length] for i in range(0, max(1, len(audio) - self.audio_length + 1), self.step)]\n      audios[-1] = crop_or_pad(audios[-1] , length=self.audio_length)\n        \n      images = [self.audio_to_image(audio) for audio in audios]\n      images = np.stack(images)\n        \n      if save:\n        path = mels_dir+f\"/{filepath}.npy\"\n        path = Path(path)\n        print(path)\n        path.parent.mkdir(exist_ok=True, parents=True)\n        np.save(str(path), images)\n      else:\n        return images","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.383550Z","iopub.execute_input":"2022-04-05T01:26:28.383965Z","iopub.status.idle":"2022-04-05T01:26:28.398895Z","shell.execute_reply.started":"2022-04-05T01:26:28.383922Z","shell.execute_reply":"2022-04-05T01:26:28.398190Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def normalize(image):\n        image = image.astype(\"float32\", copy=False) / 255.0\n        image = np.stack([image, image, image])\n        image = np.stack([image])\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.400447Z","iopub.execute_input":"2022-04-05T01:26:28.400721Z","iopub.status.idle":"2022-04-05T01:26:28.409169Z","shell.execute_reply.started":"2022-04-05T01:26:28.400687Z","shell.execute_reply":"2022-04-05T01:26:28.408417Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nle.classes_ = np.load(model_dir/classes_np)\n\ndef predict(image, this_model):\n    im = normalize(image)\n    predictions = this_model.predict(im)[0]\n    #print(predictions)\n    bird_idx = sorted(range(len(predictions)), key=lambda i: predictions[i])[:]\n    #print(bird_idx)\n    bird_name = le.inverse_transform(bird_idx)\n    #le_name_mapping = dict(zip(le.classes_.astype(str), le.transform(le.classes_)))\n    #print(le_name_mapping)\n    #print(bird_name)\n    bird_pred = {}\n    for i in range(len(bird_idx)):\n        bird_pred[ bird_name[i] ] = predictions[bird_idx[i]]\n    # print(bird_pred)\n    return bird_pred","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.411030Z","iopub.execute_input":"2022-04-05T01:26:28.411417Z","iopub.status.idle":"2022-04-05T01:26:28.424792Z","shell.execute_reply.started":"2022-04-05T01:26:28.411379Z","shell.execute_reply":"2022-04-05T01:26:28.423913Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# MelSpec Converter\nconverter = AudioToImage(step=int(DURATION*0.666*SR))\n# TF model\nmodel_ResNet50V2 = keras.models.load_model(model_dir/model_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T01:26:28.427616Z","iopub.execute_input":"2022-04-05T01:26:28.427892Z","iopub.status.idle":"2022-04-05T01:26:33.584524Z","shell.execute_reply.started":"2022-04-05T01:26:28.427866Z","shell.execute_reply":"2022-04-05T01:26:33.583636Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pred={\n  'row_id':[],\n  'target':[]\n}\n\ntest_path=input_dir+\"/test_soundscapes/\"\n#test_path=input_dir+\"/train_audio/puaioh/\"\nfiles=[f.split('.')[0] for f in sorted(os.listdir(test_path))]\n\nbirds_path=input_dir+\"/scored_birds.json\"\nwith open(birds_path) as bf:\n    birds = json.load(bf)\n\n\n\n# iterate over all test soundscapes\nfor f in files:\n    \n    #remove me \n    #f = \"XC144892\"\n    \n    p=test_path+f+'.ogg'\n    \n    d=librosa.get_duration(filename=p)\n    \n    #print(d)\n    #print(p)\n    \n    # convert image to melspectrogram\n    mels = converter(p, save=False)\n    #print(mels.shape)\n    #lbd.specshow(data=mels[0])\n    \n    \n\n    pcs=round(d/5)\n    segments = [[] for i in range(pcs)]\n      \n    for i in range(len(segments)):\n        \n        # perform inference\n        seg_pred = predict(mels[i], model_ResNet50V2)\n        \n        for b in birds:  \n            \n            #print(b)\n            #print(seg_pred[b])\n            \n            prediction = False\n            if seg_pred[b] > PRED_THRESHOLD:\n                prediction = True\n            \n            \n            segment_end=(i+1)*5   \n            row_id=f+'_'+b+'_'+str(segment_end)\n            pred['row_id'].append(row_id)\n\n            pred['target'].append(prediction)","metadata":{"executionInfo":{"elapsed":432,"status":"ok","timestamp":1645034636023,"user":{"displayName":"Attila Ambrus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaJ4A8UrN6evHJH1uiMr07w_zMQTSPfnDX2MTdnA=s64","userId":"16425370566673712155"},"user_tz":-60},"id":"eHn4mW_iFzd3","outputId":"86f41e36-aae0-457e-c0f5-21dd8369d035","papermill":{"duration":0.038005,"end_time":"2022-03-01T08:55:26.581342","exception":false,"start_time":"2022-03-01T08:55:26.543337","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-05T01:26:33.586764Z","iopub.execute_input":"2022-04-05T01:26:33.587323Z","iopub.status.idle":"2022-04-05T01:26:35.395605Z","shell.execute_reply.started":"2022-04-05T01:26:33.587285Z","shell.execute_reply":"2022-04-05T01:26:35.394795Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"cols=['row_id','target']\ndf_sub=pd.DataFrame(pred,columns=cols)","metadata":{"executionInfo":{"elapsed":529,"status":"ok","timestamp":1645034654146,"user":{"displayName":"Attila Ambrus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaJ4A8UrN6evHJH1uiMr07w_zMQTSPfnDX2MTdnA=s64","userId":"16425370566673712155"},"user_tz":-60},"id":"nA-K-d9pMg1I","outputId":"bccf2ed5-7f06-426a-e129-1083639e4722","papermill":{"duration":0.020877,"end_time":"2022-03-01T08:55:26.609442","exception":false,"start_time":"2022-03-01T08:55:26.588565","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-05T01:26:35.397527Z","iopub.execute_input":"2022-04-05T01:26:35.397785Z","iopub.status.idle":"2022-04-05T01:26:35.405129Z","shell.execute_reply.started":"2022-04-05T01:26:35.397751Z","shell.execute_reply":"2022-04-05T01:26:35.404127Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_sub.to_csv(work_dir+\"/submission.csv\", index=False)","metadata":{"executionInfo":{"elapsed":416,"status":"ok","timestamp":1645037502305,"user":{"displayName":"Attila Ambrus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgaJ4A8UrN6evHJH1uiMr07w_zMQTSPfnDX2MTdnA=s64","userId":"16425370566673712155"},"user_tz":-60},"id":"zBxRstAj1BJZ","papermill":{"duration":0.018434,"end_time":"2022-03-01T08:55:26.634725","exception":false,"start_time":"2022-03-01T08:55:26.616291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-05T01:26:35.406657Z","iopub.execute_input":"2022-04-05T01:26:35.407000Z","iopub.status.idle":"2022-04-05T01:26:35.415667Z","shell.execute_reply.started":"2022-04-05T01:26:35.406964Z","shell.execute_reply":"2022-04-05T01:26:35.414856Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.006541,"end_time":"2022-03-01T08:55:26.648193","exception":false,"start_time":"2022-03-01T08:55:26.641652","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}